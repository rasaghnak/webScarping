{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPNWsAU4id/Yt8AVB2rEhXP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rasaghnak/webScarping/blob/main/sampleWebScrap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lc4fTqpXz95s",
        "outputId": "ffa7bdad-f41f-4011-f66d-f5731de0fc9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.7.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "pip install requests beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Define the URL of the website to scrape\n",
        "url = 'https://news.google.com/home?hl=en-US&gl=US&ceid=US:en'  # Replace with the actual URL\n",
        "\n",
        "# Send a GET request to the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    html_content = response.text\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "id": "GgVak-d90WSo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Parse the HTML content using BeautifulSoup\n",
        "soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "# Extract the article titles\n",
        "# Assuming the titles are within <h2> tags with a class 'title' (you'll need to inspect the actual HTML structure of your target website)\n",
        "article_titles = soup.find_all('h2', class_='title')\n",
        "\n",
        "# Print the extracted titles\n",
        "for title in article_titles:\n",
        "    print(title.get_text())\n"
      ],
      "metadata": {
        "id": "a06CmTak1Nql"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "article_titles = soup.find_all('div', class_='article')\n",
        "for article in article_titles:\n",
        "    title = article.find('a').get_text()\n",
        "    print(title)\n"
      ],
      "metadata": {
        "id": "ihDG4JtK1VCS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "# Define the URL of the website to scrape\n",
        "url = 'https://news.google.com/home?hl=en-US&gl=US&ceid=US:en'  # Replace with the actual URL\n",
        "\n",
        "# Send a GET request to the webpage\n",
        "response = requests.get(url)\n",
        "\n",
        "# Check if the request was successful\n",
        "if response.status_code == 200:\n",
        "    html_content = response.text\n",
        "\n",
        "    # Parse the HTML content using BeautifulSoup\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    # Inspect the HTML structure to find the right tag and class\n",
        "    # Let's assume titles are within <h2> tags with class 'headline' and contain <a> tags\n",
        "    article_titles = soup.find_all('a', class_='gPFEn')\n",
        "\n",
        "    # Check if we found any titles\n",
        "    if article_titles:\n",
        "        # Print the extracted titles\n",
        "        for title in article_titles:\n",
        "            title_text = title.find('a').get_text() if title.find('a') else title.get_text()\n",
        "            print(title_text)\n",
        "    else:\n",
        "        print(\"No article titles found. Please inspect the HTML structure.\")\n",
        "else:\n",
        "    print(f\"Failed to retrieve the webpage. Status code: {response.status_code}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fh9lRpHuStvx",
        "outputId": "a1560dce-4a06-41f5-98de-bfef3a2d4171"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "U.S. in \"continuous discussions\" with Israel, Lebanon after rocket attack\n",
            "Lebanese media reports IDF strikes on oft-targeted towns of Houla and Markaba\n",
            "U.S. warned Israel against targeting Hezbollah in Beirut after deadly strike\n",
            "A Village’s Anguish Over 12 Children Lost to a Rocket Strike\n",
            "Park wildfire in California becomes largest active blaze in US\n",
            "Park Fire, Now One of the Largest in California History, Rapidly Expands Amid Dry Conditions\n",
            "Shingletown residents brace for Park Fire\n",
            "California town decimated by 2018 wildfire threatened again by state’s largest this year, as fires plague Oregon and Canada\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TaxXTQ0ETw04"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}